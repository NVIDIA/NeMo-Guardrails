import core
import avatars
import llm
import timing

# ----------------------------------
# Skill interaction flows
# ----------------------------------

@meta(exclude_from_llm=True)
flow reaction to user silence $time_s $text
  """Let the bot say something if the user was quite for the specified time."""
  user was silent $time_s
  bot inform $text

@meta(exclude_from_llm=True)
flow reaction bot question repetition for user silence $time_s $max_repetitions=1
  """Repeat previous bot question when use was silent for specified time."""
  bot asked something as $ref
  #start_new_flow_instance:
  $repetition = 0
  while $repetition < $max_repetitions
    when user was silent $time_s
      $question = $ref.text

      start GenerateValueAction(var_name="new_question_variation", instructions="Create a different variation of the following question: '{$question}'. Never repeat the same question (see interaction history above) and respond with question text within quotes.") as $llm_request
      when $llm_request.Finished() as $llm_request_result
        $prompt = $llm_request_result.return_value
      or when user started saying something
        continue

      if not is_str($prompt)
        $prompt = "So, what do you think?"
      bot ask $prompt
      $repetition = $repetition + 1
    or when user said something or bot said something
      break
    or when bot asked something
      continue

# ----------------------------------
# Bot intents
# Note: To enable the LLM prompt generation extraction use only one single statement
# -----------------------------------

flow bot express greeting
  (bot express "Hi there!"
    or bot express "Welcome!"
    or bot express "Hello!")
    and bot gesture "Wave with one hand"

flow bot express feeling well
  (bot express "I am good!"
    or bot express "I am great!")
    and (bot gesture "Thumbs up" or bot gesture "Smile")

flow bot express feeling bad
  (bot express "I am not good!"
    or bot express "I am a bit under the weather!")
    and (bot gesture "Thumbs down" or bot gesture "Sad face")

flow bot inform about service
  bot inform "You can ask or instruct me whatever you want and I will do it!"
    and bot gesture "Open up both hands making a presenting gesture"

flow bot ask how are you
  (bot say "How are you doing?"
    or bot say "How is it going?")
    and bot gesture "Pay attention to user"

flow bot make short pause
  wait 2.0

flow bot make long pause
  wait 5.0

# ----------------------------------
# User intents
# Note: To enable the LLM prompt generation extraction use only one single statement
# -----------------------------------

flow user expressed greeting
  user said "hi"
    or user said "Welcome!"
    or user said "Hello!"

flow user expressed done
  user said (regex("(?i).*done.*|.*end.*showcase.*|.*exit.*"))

flow user asked how are you
  user said "how are you"

flow user picked number guessing game showcase
  """User picked the number guessing game showcase (A)."""
  user has selected choice "game"
    or user said "I want to play the number guessing game"
    or user said "Show me the game"
    or user said "showcase A"
    or user said "First showcase"
    or user said (regex("(?i)guessing game"))

flow user picked multimodality showcase
   """User picked the multimodality showcase (B)."""
   user has selected choice "multimodality"
     or user said "Show me the multimodality showcase"
     or user said "multimodality"
     or user said "showcase B"
     or user said "Second showcase"
     or user said (regex("(?i)multimodality"))

flow user picked backchanneling showcase
  """User picked the backchanneling showcase (C)."""
  user has selected choice "backchanneling"
    or user said "Show me the backchanneling showcase"
    or user said "backchanneling"
    or user said "showcase C"
    or user said "Third showcase"
    or user said (regex("(?i)channeling|back channel"))

flow user picked posture showcase
  """User picked the posture showcase (D)."""
  user has selected choice "posture"
    or user said "Show me the posture showcase"
    or user said "posture"
    or user said "showcase D"
    or user said "Fourth showcase"
    or user said "Second last showcase"
    or user said (regex("(?i)posture"))

flow user picked proactive showcase
  """User picked the proactive showcase (E)."""
  user has selected choice "proactive"
    or user said "Show me the proactive showcase"
    or user said "proactive"
    or user said "showcase E"
    or user said "Fifth showcase"
    or user said "Last showcase"
    or user said (regex("(?i)pro\s*active|turn\s*tak[ie]"))

flow user wanted to end conversation
  """User wants to end the open conversation"""
  user said "I am done"
    or user said "I want to end this"
    or user said "Shut up"
    or user said "Let's finish this conversation"
    or user said "I want to go back"

flow user confirmed limitations
  """User confirmed to have understood the limitations of the demo"""
  user said "I understand the limitations"
    or user said "I am OK with the limitations"
    or user said "Understood. Let's continue"
    or user said (regex("(?i)confirm|ok|go|understand|limitation|start|understood|clear|okay"))

flow bot start the number guessing game
  """Bot starts the number guessing game"""
  showcase number guessing game

# ----------------------------------
# FAQs
# -----------------------------------

flow greeting faq
  user expressed greeting
  bot express greeting

flow how are you faq
  user asked how are you
  bot express feeling well
    or bot express feeling bad

flow faq
  activate greeting faq
    and how are you faq
  wait indefinitely

# ----------------------------------
# Main story
# -----------------------------------

flow check limitations with user
  start VisualInformationSceneAction(title="Limitations", support_prompts=["Please confirm by saying 'I understand the limitations'"], content=[{"text":"This demo has some limitations:"},{"text":"- Ensure you test in a quiet environment. Background noise (e.g., office chatter) will ruin the experience of the demo for you."},{"text":"- Only Chrome browsers are supported"},{"text":"- This demo highlights various Colang features and is not meant to provide a flawless user experience."}]) as $info_screen
  start bot inform "Before we start, make sure that you understand the limitations of this demo. Confirm by saying 'I understand the limitations'."
  while True
    when user was silent 20.0
      start bot say "Please confirm by saying 'I understand the limitations'."
    or when user confirmed limitations
      bot say "Great! With that out of the way, let's start the demo"
      break
    or when user said something
      bot say "Sorry, I am not sure if this was a confirmation. Can you rephrase?."


flow showcase selector
  activate tracking visual choice selection state

  $showcase_selection_ui = None
  global $bot_talking_state

  while True
    if $showcase_selection_ui == None
      activate continuation on unhandled user utterance
      activate handling bot talking interruption "inform"
      start VisualChoiceSceneAction(prompt= "Pick a showcase", support_prompts=["You can click on any option below","Or just say the 'Option C'","Or you can say 'I want to play the guessing game'"],choice_type="selection", allow_multiple_choices=False, options= [{"id": "game", "text": "A: Guessing Game", "image":"number 2 horizontal orientation"}, {"id": "multimodality", "text": "B: Multimodality", "image":"newton s cradle horizontal orientation"}, {"id": "backchanneling", "text": "C: Backchanneling", "image":"channel mixer horizontal orientation"}, {"id": "posture", "text": "D: Posture modulation", "image":"gauge horizontal orientation"}, {"id": "proactive", "text": "E: Proactive turn-taking", "image":"speech bubble horizontal orientation"}]) as $showcase_selection_ui
      start bot inform "Please pick one of the showcases."

    when user was silent 15.0
      log "user was silent"
      start llm continue interaction as $llm_continuation
      when $llm_continuation.Finished()
        log "user was silent llm response done"
      or when user started saying something
        log "user started saying something while llm response generation"
        if $bot_talking_state == False
          send $llm_continuation.Stop()
          log "user said something during bot thinking (user silent llm response generation)"

    or when user picked number guessing game showcase
      send $showcase_selection_ui.Stop()
      deactivate continuation on unhandled user utterance
      deactivate handling bot talking interruption
      $showcase_selection_ui = None
      bot inform "Great! You picked the number guessing game!"
      showcase number guessing game

    or when user picked multimodality showcase
      send $showcase_selection_ui.Stop()
      deactivate continuation on unhandled user utterance
      deactivate handling bot talking interruption
      $showcase_selection_ui = None
      bot inform "Great! You picked the multimodality showcase!"
      showcase multimodality

    or when user picked backchanneling showcase
      send $showcase_selection_ui.Stop()
      deactivate continuation on unhandled user utterance
      deactivate handling bot talking interruption
      $showcase_selection_ui = None
      bot inform "Great! You picked the backchanneling example!"
      showcase backchannelling interaction

    or when user picked posture showcase
      send $showcase_selection_ui.Stop()
      deactivate continuation on unhandled user utterance
      deactivate handling bot talking interruption
      $showcase_selection_ui = None
      bot inform "Great! You picked the posture showcase!"
      showcase posture capabilities

    or when user picked proactive showcase
      send $showcase_selection_ui.Stop()
      deactivate continuation on unhandled user utterance
      deactivate handling bot talking interruption
      $showcase_selection_ui = None
      bot inform "Great! You picked the proactive turn-taking example!"
      showcase proactive turn taking

    or when user wanted to end conversation
      send $showcase_selection_ui.Stop()
      $showcase_selection_ui = None
      bot say "Ok! It was great talking to you! Goodbye!"
        and bot gesture "Waving hands"
      start bot posture "Idle" as $idle_posture
      wait 10.0
      send $idle_posture.Stop()
      bot say "Welcome back!"

@meta(exclude_from_llm=True)
flow main
  #activate notification of unexpected user utterance
  activate ignored_utterance_action_bugfix
  activate notification of undefined flow start "Excuse me, what did you say?"
  activate notification of colang errors "Excuse me, what did you say?"
  activate automating intent detection
  activate tracking bot talking state
  activate managing idle posture
  #activate faq

  start scene show textual information $title="Welcome to the Tech Demo of Colang 2.0" $text="" $header_image="https://blogs.nvidia.com/wp-content/uploads/2023/04/NeMo-Guardrails-KV-x1280.jpg" as $welcome_ui
  bot say "Welcome to a demo of Colang 2.0 and some of it's upcoming features!"
    and bot gesture "Welcome user, wave hands"
  send $welcome_ui.Stop()

  #check limitations with user
  activate showcase selector

  #showcase number guessing game
  #showcase multimodality
  #showcase backchannelling interaction
  #showcase posture capabilities
  #showcase proactive turn taking
  wait indefinitely

@meta(exclude_from_llm=True)
@loop("ignored_action_bugfix")
flow ignored_utterance_action_bugfix
  global $number_of_failed_utterance_actions
  if $number_of_failed_utterance_actions == None
    $number_of_failed_utterance_actions = 0
  match StartUtteranceBotAction() as $event
  start_new_flow_instance:
  start wait 3.0 as $timer_ref
  when $timer_ref.Finished()
    # After 3 consecutive fails we will no longer send a Finished event to let the process become idle and terminated
    if $number_of_failed_utterance_actions < 3
      send UtteranceBotActionFinished(action_uid=$event.action_uid, final_script="", is_success=False, failure_reason="ActionStarted event timeout")
      log "ignored_utterance_action_bugfix triggered for action: {$event.action_uid}"
    $number_of_failed_utterance_actions = $number_of_failed_utterance_actions + 1
  or when UtteranceBotActionStarted(action_uid=$event.action_uid)
    $number_of_failed_utterance_actions = 0
