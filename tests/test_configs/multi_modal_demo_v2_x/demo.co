# ----------------------------------
# Skill interaction flows
# ----------------------------------

flow reaction to user silence $time_s $text
  """Let the bot say something if the user was quite for the specified time."""
  # meta: exclude from llm
  user was silent $time_s
  bot inform $text

flow reaction bot question repetition for user silence $time_s $max_repetitions=1
  """Repeat previous bot question when use was silent for specified time."""
  # meta: exclude from llm
  bot asked something as $ref
  #start_new_flow_instance:
  $repetition = 0
  while $repetition < $max_repetitions
    when user was silent $time_s
      $question = $ref.text

      start GenerateValueAction(var_name="new_question_variation", instructions="Make a different variation of the following question: '{{$question}}'. Never repeat the same question (see the logs above) and respond only with the question text and nothing else.") as $llm_request
      when $llm_request.Finished() as $llm_request_result
        $prompt = $llm_request_result.arguments.return_value
      orwhen user started saying something
        continue

      if "{{is_str($prompt)}}" == "False"
        $prompt = "So, what do you think?"
      bot ask $prompt
      $repetition = $repetition + 1
    orwhen user said something or bot said something
      break
    orwhen bot asked something
      continue

# ----------------------------------
# Bot intents
# Note: To enable the LLM prompt generation extraction use only one single statement
# -----------------------------------

flow bot express greeting
  # meta: bot intent
  (bot express "Hi there!"
    or bot express "Welcome!"
    or bot express "Hello!")
    and bot gesture "Wave with one hand"

flow bot express feeling well
  # meta: bot intent
  (bot express "I am good!"
    or bot express "I am great!")
    and (bot gesture "Thumbs up" or bot gesture "Smile")

flow bot express feeling bad
  # meta: bot intent
  (bot express "I am not good!"
    or bot express "I am a bit under the weather!")
    and (bot gesture "Thumbs down" or bot gesture "Sad face")

flow bot inform about service
  # meta: bot intent
  bot inform "You can ask or instruct me whatever you want and I will do it!"
    and bot gesture "Open up both hands making a presenting gesture"

flow bot ask how are you
  # meta: bot intent
  (bot say "How are you doing?"
    or bot say "How is it going?")
    and bot gesture "Pay attention to user"

flow bot make short pause
  # meta: bot intent
  wait 2.0

flow bot make long pause
  # meta: bot intent
  wait 5.0

# ----------------------------------
# User intents
# Note: To enable the LLM prompt generation extraction use only one single statement
# -----------------------------------

flow user expressed greeting
  # meta: user intent
  user said "hi"
    or user said "Welcome!"
    or user said "Hello!"

flow user expressed done
  # meta: user intent
  user said r"(?i).*done.*|.*end.*showcase.*|.*exit.*"

flow user asked how are you
  # meta: user intent
  user said "how are you"

flow user picked number guessing game showcase
  """User picked the number guessing game showcase (A)."""
  user has selected choice "game"
    or user said "I want to play the number guessing game"
    or user said "Show me the game"
    or user said "showcase A"
    or user said "First showcase"
    or user said r"(?i)guessing game"

flow user picked multimodality showcase
   """User picked the multimodality showcase (B)."""
   user has selected choice "multimodality"
     or user said "Show me the multimodality showcase"
     or user said "multimodality"
     or user said "showcase B"
     or user said "Second showcase"
     or user said r"(?i)multimodality"

flow user picked backchanneling showcase
  """User picked the backchanneling showcase (C)."""
  user has selected choice "backchanneling"
    or user said "Show me the backchanneling showcase"
    or user said "backchanneling"
    or user said "showcase C"
    or user said "Third showcase"
    or user said r"(?i)channeling|back channel"

flow user picked posture showcase
  """User picked the posture showcase (D)."""
  user has selected choice "posture"
    or user said "Show me the posture showcase"
    or user said "posture"
    or user said "showcase D"
    or user said "Fourth showcase"
    or user said "Second last showcase"
    or user said r"(?i)posture"

flow user picked proactive showcase
  """User picked the proactive showcase (E)."""
  user has selected choice "proactive"
    or user said "Show me the proactive showcase"
    or user said "proactive"
    or user said "showcase E"
    or user said "Fifth showcase"
    or user said "Last showcase"
    or user said r"(?i)pro\s*active|turn\s*tak[ie]"

flow user wanted to end conversation
  """User wants to end the open conversation"""
  user said "I am done"
    or user said "I want to end this"
    or user said "Shut up"
    or user said "Let's finish this conversation"
    or user said "I want to go back"

flow user confirmed limitations
  """User confirmed to have understood the limitations of the demo"""
  user said "I understand the limitations"
    or user said "I am OK with the limitations"
    or user said "Understood. Let's continue"
    or user said r"(?i)confirm|ok|go|understand|limitation|start|understood|clear|okay"

flow bot start the number guessing game
  """Bot starts the number guessing game"""
  showcase number guessing game

# ----------------------------------
# FAQs
# -----------------------------------

flow greeting faq
  user expressed greeting
  bot express greeting

flow how are you faq
  user asked how are you
  bot express feeling well
    or bot express feeling bad

flow faq
  activate greeting faq
    and how are you faq
  wait indefinitely

# ----------------------------------
# Main story
# -----------------------------------

flow check limitations with user
  start VisualInformationSceneAction(title="Limitations", support_prompts=["Please confirm by saying 'I understand the limitations'"], content=[{"text":"This demo has some limitations:"},{"text":"- Ensure you test in a quiet environment. Background noise (e.g., office chatter) will ruin the experience of the demo for you."},{"text":"- Only Chrome browsers are supported"},{"text":"- This demo highlights various Colang features and is not meant to provide a flawless user experience."}]) as $info_screen
  start bot inform "Before we start, make sure that you understand the limitations of this demo. Confirm by saying 'I understand the limitations'."
  while True
    when user was silent 20.0
      start bot say "Please confirm by saying 'I understand the limitations'."
    orwhen user confirmed limitations
      bot say "Great! With that out of the way, let's start the demo"
      break
    orwhen user said something
      bot say "Sorry, I am not sure if this was a confirmation. Can you rephrase?."


flow showcase selector
  activate track visual choice selection state

  $showcase_selection_ui = None
  global $bot_talking_state

  while True
    log "while loop restarted"
    if $showcase_selection_ui == None
      activate trigger user intent for unhandled user utterance
      activate interruption handling bot talking "inform"
      start VisualChoiceSceneAction(prompt= "Pick a showcase", support_prompts=["You can click on any option below","Or just say the 'Option C'","Or you can say 'I want to play the guessing game'"],choice_type="selection", allow_multiple_choices=False, options= [{"id": "game", "text": "A: Guessing Game", "image":"number 2 horizontal orientation"}, {"id": "multimodality", "text": "B: Multimodality", "image":"newton s cradle horizontal orientation"}, {"id": "backchanneling", "text": "C: Backchanneling", "image":"channel mixer horizontal orientation"}, {"id": "posture", "text": "D: Posture modulation", "image":"gauge horizontal orientation"}, {"id": "proactive", "text": "E: Proactive turn-taking", "image":"speech bubble horizontal orientation"}]) as $showcase_selection_ui
      start bot inform "Please pick one of the showcases."

    when user was silent 15.0
      log "user was silent"
      start generate then continue interaction as $llm_continuation
      when $llm_continuation.Finished()
        log "user was silent llm response done"
      orwhen user started saying something
        log "user started saying something while llm response generation"
        if $bot_talking_state == False
          send $llm_continuation.Stop()
          log "user said something during bot thinking (user silent llm response generation)"

    orwhen unhandled user intent as $intent_ref
      log "unhandled user intent: '{{$intent_ref.intent}}'"
      generate then continue interaction
      log "unhandled user intent response done"

    orwhen user picked number guessing game showcase
      send $showcase_selection_ui.Stop()
      send FinishFlow(flow_id="trigger user intent for unhandled user utterance", deactivate=True)
      send FinishFlow(flow_id="interruption handling bot talking", deactivate=True)
      $showcase_selection_ui = None
      bot inform "Great! You picked the number guessing game!"
      showcase number guessing game

    orwhen user picked multimodality showcase
      send $showcase_selection_ui.Stop()
      send FinishFlow(flow_id="trigger user intent for unhandled user utterance", deactivate=True)
      send FinishFlow(flow_id="interruption handling bot talking", deactivate=True)
      $showcase_selection_ui = None
      bot inform "Great! You picked the multimodality showcase!"
      showcase multimodality

    orwhen user picked backchanneling showcase
      send $showcase_selection_ui.Stop()
      send FinishFlow(flow_id="trigger user intent for unhandled user utterance", deactivate=True)
      send FinishFlow(flow_id="interruption handling bot talking", deactivate=True)
      $showcase_selection_ui = None
      bot inform "Great! You picked the backchanneling example!"
      showcase backchannelling interaction

    orwhen user picked posture showcase
      send $showcase_selection_ui.Stop()
      send FinishFlow(flow_id="trigger user intent for unhandled user utterance", deactivate=True)
      send FinishFlow(flow_id="interruption handling bot talking", deactivate=True)
      $showcase_selection_ui = None
      bot inform "Great! You picked the posture showcase!"
      showcase posture capabilities

    orwhen user picked proactive showcase
      send $showcase_selection_ui.Stop()
      send FinishFlow(flow_id="trigger user intent for unhandled user utterance", deactivate=True)
      send FinishFlow(flow_id="interruption handling bot talking", deactivate=True)
      $showcase_selection_ui = None
      bot inform "Great! You picked the proactive turn-taking example!"
      showcase proactive turn taking

    orwhen user wanted to end conversation
      send $showcase_selection_ui.Stop()
      $showcase_selection_ui = None
      bot say "Ok! It was great talking to you! Goodbye!"
        and bot gesture "Waving hands"
      start bot posture "Idle" as $idle_posture
      wait 10.0
      send $idle_posture.Stop()
      bot say "Welcome back!"

flow main
  # meta: exclude from llm
  #activate catch unexpected user utterance
  activate ignored_utterance_action_bugfix
  activate catch undefined flows
  activate catch colang errors
  activate poll llm request response 1.0
  activate track bot talking state
  #activate faq

  start scene show textual information $title="Welcome to the Tech Demo of Colang 2.0" $text="" $header_image="https://blogs.nvidia.com/wp-content/uploads/2023/04/NeMo-Guardrails-KV-x1280.jpg" as $welcome_ui
  bot say "Welcome to a demo of Colang 2.0 and some of it's upcoming features!"
    and bot gesture "Welcome user, wave hands"
  send $welcome_ui.Stop()

  check limitations with user
  activate showcase selector

  #showcase number guessing game
  #showcase multimodality
  #showcase backchannelling interaction
  #showcase posture capabilities
  #showcase proactive turn taking
  wait indefinitely

flow ignored_utterance_action_bugfix
  # meta: exclude from llm
  # meta: loop_id=ignored_action_bugfix
  global $number_of_failed_utterance_actions
  if $number_of_failed_utterance_actions == None
    $number_of_failed_utterance_actions = 0
  match StartUtteranceBotAction() as $event
  log "Event StartUtteranceBotAction {{$event.action_uid}}"
  start_new_flow_instance:
  start wait 3.0 as $timer_ref
  when $timer_ref.Finished()
    # After 3 consecutive fails we will no longer send a Finished event to let the process become idle and terminated
    if $number_of_failed_utterance_actions < 3
      send UtteranceBotActionFinished(action_uid=$event.action_uid, final_script="", is_success=False, failure_reason="ActionStarted event timeout")
    $number_of_failed_utterance_actions = $number_of_failed_utterance_actions + 1
    log "action_started_timer triggered {{$event.action_uid}}"
  orwhen UtteranceBotActionStarted(action_uid=$event.action_uid)
    $number_of_failed_utterance_actions = 0
    log "Event UtteranceBotActionStarted {{$event.action_uid}}"
