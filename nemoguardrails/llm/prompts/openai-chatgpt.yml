# Prompts for OpenAI ChatGPT.
prompts:
  - task: generate_user_intent
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: "This is how the user talks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    output_parser: "user_intent"

  - task: generate_user_intent
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    mode: compact
    output_parser: "user_intent"

  - task: generate_next_steps
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: "This is how the bot thinks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    output_parser: "bot_intent"

  - task: generate_bot_message
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: |-
          {% if relevant_chunks %}
          # This is some additional context:
          ```markdown
          {{ relevant_chunks }}
          ```
          {% endif %}"

      - type: system
        content: "This is how the bot talks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    output_parser: "bot_message"

  - task: generate_value
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: "This is how the bot thinks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

      - type: system
        content: |-
          {{ instructions }}

      - type: assistant
        content: "${{ var_name }} ="
