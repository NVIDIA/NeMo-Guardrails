# Prompts for OpenAI ChatGPT.
prompts:
  - task: generate_user_intent
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: "This is how the user talks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    output_parser: "user_intent"

  - task: generate_user_intent
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    mode: compact
    output_parser: "user_intent"

  - task: generate_next_steps
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: "This is how the bot thinks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    output_parser: "bot_intent"

  - task: generate_bot_message
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: |-
          {% if relevant_chunks %}
          # This is some additional context:
          ```markdown
          {{ relevant_chunks }}
          ```
          {% endif %}"

      - type: system
        content: "This is how the bot talks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

    output_parser: "bot_message"

  - task: generate_value
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"

      - "{{ sample_conversation | to_messages }}"

      - type: system
        content: "This is how the bot thinks:"

      - "{{ examples | to_messages}}"

      - type: system
        content: "This is the current conversation between the user and the bot:"

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"

      - type: system
        content: |-
          {{ instructions }}

      - type: assistant
        content: "${{ var_name }} ="

  # Colang 2 prompts below.

  # Prompt for detecting the user message canonical form.
  - task: generate_user_intent_from_user_action
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"
      - "{{ sample_conversation | to_messages_v2 }}"

      - type: system
        content: |-
          "These are the most likely user intents:"
          {{ examples }}

      - type: system
        content: "This is the current conversation between the user and the bot:"
      - "{{ history | colang | to_messages_v2}}"

      - type: user
        content: "user action: {{ user_action }}"

      - type: system
        content: "Derive `user intent:` from user action considering the intents from section 'These are the most likely user intents':"

  - task: generate_user_intent_and_bot_action_from_user_action
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"
      - "{{ sample_conversation | to_messages_v2 }}"

      - type: system
        content: |
          {% if context.relevant_chunks %}
          # This is some additional context:
          ```markdown
          {{ context.relevant_chunks }}
          ```
          {% endif %}

      - type: system
        content: |-
          "These are the most likely user intents:"
          {{ examples }}

      - type: system
        content: "This is the current conversation between the user and the bot:"
      - "{{ history | colang | to_messages_v2}}"

      - type: user
        content: "user action: {{ user_action }}"

      - type: system
        content: "Continuation of the interaction starting with a `user intent:` from the section 'These are the most likely user intents':"

  # Prompt for generating the value of a context variable.
  - task: generate_value_from_instruction
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: |
          {{ general_instructions }}

          Your task is to generate value for the ${{ var_name }} variable..
          Do not provide any explanations, just output value.

      - type: system
        content: "This is how a conversation between a user and the bot can go:"
      - "{{ sample_conversation | to_messages_v2 }}"

      - type: system
        content: "This is the current conversation between the user and the bot:"
      - "{{ history | colang | to_messages_v2}}"

      - type: system
        content: |
          Follow these instruction `{{ instructions }}` to generate a value that is assigned to:
          ${{ var_name }} =

  # Prompt for generating a flow from instructions.
  - task: generate_flow_from_instructions
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    content: |-
      # Example flows:
      {{ examples }}

      # Complete the following flow based on its instruction:
      flow {{ flow_name }}
        """{{ instructions }}"""

  # Prompt for generating a flow from name.
  - task: generate_flow_from_name
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: |
          {{ general_instructions }}

          Your task is to generate a flow from the provided flow name ${{ flow_name }}.
          Do not provide any explanations, just output value.

      - type: system
        content: "This is the current conversation between the user and the bot:"
      - "{{ history | colang | to_messages_v2}}"

      - type: system
        content: |-
          Example flows:
          {{ examples }}

      - type: system
        content: |-
          Complete the following flow based on its name:
          flow {{ flow_name }}
    stop:
      - "\nflow"

  # Prompt for generating the continuation for the current conversation.
  - task: generate_flow_continuation
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: "{{ general_instructions }}"

      - type: system
        content: "This is how a conversation between a user and the bot can go:"
      - "{{ sample_conversation | to_messages_v2 }}"

      - type: system
        content: "This is the current conversation between the user and the bot:"
      - "{{ history | colang | to_messages_v2 }}"

      - type: system
        content: |
          {% if context.relevant_chunks %}
          # This is some additional context:
          ```markdown
          {{ context.relevant_chunks }}
          ```
          {% endif %}

      - type: system
        content: "Continuation of interaction:"

  - task: generate_flow_continuation_from_flow_nld
    models:
      - openai/gpt-3.5-turbo
      - openai/gpt-4
    messages:
      - type: system
        content: |-
            {{ flow_nld }}
