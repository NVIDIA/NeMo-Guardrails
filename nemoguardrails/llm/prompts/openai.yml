# Collection of all the prompts
prompts:
    # GENERAL PROMPTS

    - task: general
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          {{ general_instructions }}

          {% if relevant_chunks != None and relevant_chunks != '' %}
            This is some relevant context:
            ```markdown
            {{ relevant_chunks }}
            ```
          {% endif %}

          {{ history | user_assistant_sequence }}
          Assistant:

    # Prompt for detecting the user message canonical form.
    - task: generate_user_intent
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          # This is how the user talks:
          {{ examples }}

          # This is the current conversation between the user and the bot:
          # Choose intent from this list: {{ potential_user_intents }}
          {{ sample_conversation | first_turns(2) }}
          {{ history | colang }}

    # Prompt for generating the next steps.
    - task: generate_next_steps
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation | remove_text_messages }}

          # This is how the bot thinks:
          {{ examples | remove_text_messages}}

          # This is the current conversation between the user and the bot:
          {{ sample_conversation | first_turns(2) | remove_text_messages}}
          {{ history | colang | remove_text_messages}}

    # Prompt for generating the bot message from a canonical form.
    - task: generate_bot_message
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          {% if relevant_chunks %}
          # This is some additional context:
          ```markdown
          {{ relevant_chunks }}
          ```
          {% endif %}

          # This is how the bot talks:
          {{ examples }}

          # This is the current conversation between the user and the bot:
          {{ sample_conversation | first_turns(2) }}
          {{ history | colang }}

    # Prompt for generating the user intent, next steps and bot message in a single call.
    - task: generate_intent_steps_message
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          # For each user message, generate the next steps and finish with the bot message.
          # These are some examples how the bot thinks:
          {{ examples }}

          # This is the current conversation between the user and the bot:
          {{ sample_conversation | first_turns(2) }}
          {{ history | colang }}

    # Prompt for generating the value of a context variable.
    - task: generate_value
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          # This is how the bot thinks:
          {{ examples }}

          # This is the current conversation between the user and the bot:
          {{ sample_conversation | first_turns(2) }}
          {{ history | colang }}
          # {{ instructions }}
          ${{ var_name }} =

    # Colang 2.x prompts below.

    # Prompt for detecting the user message canonical form.
    - task: generate_user_intent_from_user_action
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          # These are the most likely user intents:
          {{ examples }}

          # This is the current conversation between the user and the bot:
          {{ history | colang }}

          # Continuation of interaction using only specified user intents from the section 'These are the most likely user intents:':
          user action: {{ user_action }}
          user intent:
      stop:
          - "\n"

    - task: generate_user_intent_and_bot_action_from_user_action
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          # These are the most likely user intents:
          {{ examples }}


          {% if context.relevant_chunks %}
          # This is some additional context:
          ```markdown
          {{ context.relevant_chunks }}
          ```
          {% endif %}

          # This is the current conversation between the user and the bot:
          {{ history | colang }}

          # Continuation of interaction using only specified user intents from the section 'These are the most likely user intents:':
          user action: {{ user_action }}
          user intent:
      stop:
          - "\nuser intent:"

    # Prompt for generating the value of a context variable.
    - task: generate_value_from_instruction
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          # This is the current conversation between the user and the bot:
          {{ history | colang }}

          # {{ instructions }}
          ${{ var_name }} =
      stop:
          - "\n"

    # Prompt for generating a flow from instructions.
    - task: generate_flow_from_instructions
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          # Example flows:
          {{ examples }}

          # Complete the following flow based on its instruction:
          flow {{ flow_name }}
            """{{ instructions }}"""

    # Prompt for generating a flow from name.
    - task: generate_flow_from_name
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          # Example flows:
          {{ examples }}

          # Complete the following flow based on its name:
          flow {{ flow_name }}
      stop:
          - "\nflow"

      # Prompt for generating the continuation for the current conversation.
    - task: generate_flow_continuation
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          """
          {{ general_instructions }}
          """

          # This is how a conversation between a user and the bot can go:
          {{ sample_conversation }}

          {% if context.relevant_chunks %}
          # This is some additional context:
          ```markdown
          {{ context.relevant_chunks }}
          ```
          {% endif %}

          # This is the current conversation between the user and the bot:
          {{ history | colang }}


          bot intent:

    - task: generate_flow_continuation_from_flow_nld
      models:
          - openai/gpt-3.5-turbo-instruct
      content: |-
          {{ flow_nld }}
